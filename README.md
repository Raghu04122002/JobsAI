# JobAI â€” AI-Powered Career Assistant

> Upload your resume, paste job descriptions, and let AI analyze matches, tailor resume bullets, and generate cover letters â€” all in one place.

![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python)
![Django](https://img.shields.io/badge/Django-5.x-green?logo=django)
![Next.js](https://img.shields.io/badge/Next.js-14-black?logo=next.js)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue?logo=postgresql)
![Docker](https://img.shields.io/badge/Docker-Compose-blue?logo=docker)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-412991?logo=openai)

---

## âœ¨ Features

| Feature | Description |
|---|---|
| **Dashboard** | Upload & manage resumes, view application stats, quick overview of saved jobs |
| **Analyzer** | Add job descriptions, select a resume + job, and run AI-powered match scoring with keyword analysis & improvement suggestions |
| **Tailor** | Select a job and auto-generate tailored resume bullets + a cover letter using AI |
| **Applications** | Full CRUD tracker â€” add, edit, and delete job applications with status tracking (Applied, Interview, Rejected, Offer) |
| **Auth** | Email-based signup/login with JWT (access + refresh tokens), auto-refresh on 401 |

---

## ğŸ—ï¸ Tech Stack

### Backend
- **Django 5 + DRF** â€” REST API with token authentication
- **PostgreSQL 16** â€” Relational database
- **ChromaDB** â€” Vector store for resume/job embeddings
- **OpenAI GPT-4o-mini** â€” LLM for analysis, tailoring, and matching
- **Gunicorn** â€” Production WSGI server

### Frontend
- **Next.js 14** (App Router) â€” React framework with SSR
- **TypeScript** â€” Type-safe frontend code
- **Tailwind CSS** â€” Utility-first styling

### Infrastructure
- **Docker Compose** â€” Full-stack orchestration (4 services)
- **Nginx** â€” Reverse proxy, static/media serving

---

## ğŸ“ Project Structure

```
jobai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ accounts/          # Custom user model, signup endpoint
â”‚   â”œâ”€â”€ resumes/           # Upload, text extraction, vector indexing
â”‚   â”œâ”€â”€ jobs/              # Job descriptions, vector indexing
â”‚   â”œâ”€â”€ applications/      # Application tracker CRUD
â”‚   â”œâ”€â”€ ai_engine/         # CRAG service, prompts, AI views
â”‚   â”‚   â””â”€â”€ services/      # crag.py, vector_store.py, openai_client.py

â”‚   â”œâ”€â”€ core/              # Permissions, exception handling
â”‚   â”œâ”€â”€ career_copilot/    # Django settings, URLs, Gunicorn config
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # Next.js pages (login, signup, dashboard, etc.)
â”‚   â”‚   â”œâ”€â”€ components/    # Shared components (NavBar)
â”‚   â”‚   â””â”€â”€ lib/           # API client, auth helpers, config
â”‚   â”œâ”€â”€ middleware.ts       # Route protection
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ deploy/nginx/           # Nginx reverse proxy config
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### Prerequisites

- [Docker](https://docs.docker.com/get-docker/) & Docker Compose
- An [OpenAI API key](https://platform.openai.com/api-keys)

### 1. Clone the repo

```bash
git clone https://github.com/YOUR_USERNAME/jobai.git
cd jobai
```

### 2. Configure environment

```bash
cp .env.example .env
```

Edit `.env` and set your values:

```env
# Required â€” set your OpenAI key
OPENAI_API_KEY=sk-your-key-here

# Required â€” change for production
DJANGO_SECRET_KEY=your-secure-random-key

# Optional â€” defaults work for local development
POSTGRES_DB=
POSTGRES_USER=
POSTGRES_PASSWORD=
```

### 3. Build and run

```bash
docker compose up --build -d
```

### 4. Open the app

Open `http://localhost` in your browser and sign up at `/signup` to get started.

---

### 5. Create an account

Sign up at `http://localhost/signup`.

---

## ğŸ”Œ API Reference

### Authentication
| Method | Endpoint | Description |
|---|---|---|
| `POST` | `/api/auth/signup/` | Create a new account |
| `POST` | `/api/token/` | Get JWT token pair |
| `POST` | `/api/token/refresh/` | Refresh access token |

### Resumes
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/api/resumes/` | List user's resumes |
| `POST` | `/api/resumes/` | Upload a resume (multipart) |
| `PATCH` | `/api/resumes/{id}/` | Update resume title |
| `DELETE` | `/api/resumes/{id}/` | Delete a resume |

### Jobs
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/api/jobs/` | List user's saved jobs |
| `POST` | `/api/jobs/` | Save a job description |
| `PATCH` | `/api/jobs/{id}/` | Update a job |
| `DELETE` | `/api/jobs/{id}/` | Delete a job |

### Applications
| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/api/applications/` | List applications |
| `POST` | `/api/applications/` | Add an application |
| `PUT` | `/api/applications/{id}/` | Update an application |
| `DELETE` | `/api/applications/{id}/` | Delete an application |

### AI (Tailor & Analyzer)
| Method | Endpoint | Description |
|---|---|---|
| `POST` | `/api/copilot/tailor/` | Generate tailored resume bullets + cover letter |
| `POST` | `/api/copilot/match/` | Match a resume against a job with scoring |

---

## ğŸ¤– AI Architecture (CRAG)

The AI engine uses **Corrective Retrieval-Augmented Generation** (CRAG):

```
User Query â†’ Retrieve Context (ChromaDB) â†’ Score Relevance (LLM)
                                                    â”‚
                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                     â”‚ Score â‰¥ threshold?          â”‚
                                     â”‚   Yes â†’ Generate Answer     â”‚
                                     â”‚   No  â†’ Retry (wider k)     â”‚
                                     â”‚         â†’ up to 2 retries   â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Retrieval** â€” ChromaDB vectors scoped per user
- **Scoring** â€” LLM rates context relevance (1â€“10)
- **Retry** â€” Up to 2 retries with larger retrieval window
- **Fallback** â€” Uses best available context; returns guidance if none exists

---

## ğŸ—„ï¸ Database Indexes

| Table | Index Fields |
|---|---|
| `resumes` | `(user, created_at)` |
| `jobs` | `(user, created_at)`, `(company)` |
| `applications` | `(user, status)`, `(user, applied_date)`, `(company)` |


All querysets are filtered by `request.user` with object-level ownership permissions.

---

## ğŸ“ˆ Scaling Considerations

- **Horizontal scale** â€” Multiple Gunicorn workers + container replicas
- **Static/Media** â€” Move to S3 + CDN for high traffic
- **Caching** â€” Add Redis for sessions, rate limiting, token throttling
- **Async** â€” Celery + message queue for extraction/embedding pipelines
- **Vector DB** â€” Migrate to managed/HA vector store as usage grows
- **Observability** â€” Structured logging, tracing, error rates, token/cost metrics


## ğŸ› ï¸ Development

### Run migrations manually

```bash
docker compose exec backend python manage.py makemigrations
docker compose exec backend python manage.py migrate
```

### View logs

```bash
docker compose logs -f backend
docker compose logs -f frontend
```

### Rebuild after code changes

```bash
docker compose up --build -d
```
ğŸ¤ Contributing
Contributions are welcome! Please feel free to submit a Pull Request.

ğŸ“„ License
MIT License - feel free to use this project for your own purposes.



Made by Raghu

